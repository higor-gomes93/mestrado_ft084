{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d98d804ada834ca68b7ced0642d33dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4659511662d45db9401a5c164c66c3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ca8374a8a0f41f29f64b50ae65378fa",
              "IPY_MODEL_8560c2c709c24d879c5069cfad00105d"
            ]
          }
        },
        "b4659511662d45db9401a5c164c66c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ca8374a8a0f41f29f64b50ae65378fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_505b42cee2cd46ffac43f33437690790",
            "_dom_classes": [],
            "description": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.1.json: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 23895,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23895,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d73fe2ddab1d4085a6d2c5e02dd0ebc3"
          }
        },
        "8560c2c709c24d879c5069cfad00105d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5510b3cb91f34c6dbdb307ef2e4b3257",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 139k/? [00:00&lt;00:00, 2.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa8f32df51084369948592a54d857b77"
          }
        },
        "505b42cee2cd46ffac43f33437690790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d73fe2ddab1d4085a6d2c5e02dd0ebc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5510b3cb91f34c6dbdb307ef2e4b3257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa8f32df51084369948592a54d857b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "114151d37cab49b59f37d910be7e47e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57daf50cce7e4cdd9dc3e6a89caf6de2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18e81a81c4c949f296c6ee7586dd99df",
              "IPY_MODEL_2f2cecb520384a338a61d46c85a91a80"
            ]
          }
        },
        "57daf50cce7e4cdd9dc3e6a89caf6de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18e81a81c4c949f296c6ee7586dd99df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d3819bd0c9274ba4a616b414d8e9d101",
            "_dom_classes": [],
            "description": "Downloading http://nlp.stanford.edu/software/stanza/1.2.1/en/default.zip: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411784510,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411784510,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69f6588425af4ecc8c1ce3693e088b7f"
          }
        },
        "2f2cecb520384a338a61d46c85a91a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5b3cb8a2fcfc4dca9a4e62665dffb330",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [01:19&lt;00:00, 5.17MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5e4842c4b4c4f2da0902e6a56fd8c33"
          }
        },
        "d3819bd0c9274ba4a616b414d8e9d101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69f6588425af4ecc8c1ce3693e088b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b3cb8a2fcfc4dca9a4e62665dffb330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5e4842c4b4c4f2da0902e6a56fd8c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/higor-gomes93/mestrado_ft084/blob/main/Twitter_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTNEbt10ety-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d98d804ada834ca68b7ced0642d33dc5",
            "b4659511662d45db9401a5c164c66c3a",
            "2ca8374a8a0f41f29f64b50ae65378fa",
            "8560c2c709c24d879c5069cfad00105d",
            "505b42cee2cd46ffac43f33437690790",
            "d73fe2ddab1d4085a6d2c5e02dd0ebc3",
            "5510b3cb91f34c6dbdb307ef2e4b3257",
            "aa8f32df51084369948592a54d857b77",
            "114151d37cab49b59f37d910be7e47e5",
            "57daf50cce7e4cdd9dc3e6a89caf6de2",
            "18e81a81c4c949f296c6ee7586dd99df",
            "2f2cecb520384a338a61d46c85a91a80",
            "d3819bd0c9274ba4a616b414d8e9d101",
            "69f6588425af4ecc8c1ce3693e088b7f",
            "5b3cb8a2fcfc4dca9a4e62665dffb330",
            "c5e4842c4b4c4f2da0902e6a56fd8c33"
          ]
        },
        "outputId": "a5c1233c-ba34-488b-f895-a54dc5fe1555"
      },
      "source": [
        "#Código para carregar  o arquvo  corona_tweets_463.csv salvo no GoogleDrive.\n",
        "#Código para carregar os tweet que serão utilizados: 150.000 regsitros do arquivo corona_tweets_463.csv\n",
        "from google.colab import drive\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import clear_output\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "working_directory = 'MyDrive/TrabalhoFT' #@param {type:\"string\"}\n",
        "wd=\"/content/drive/\"+working_directory\n",
        "os.chdir(wd)\n",
        "\n",
        "dirpath = os.getcwd()\n",
        "print(\"current directory is : \" + dirpath)\n",
        "\n",
        "\n",
        "#Carregando o arquivo do googleDrive sem cabeçalho definido no arquivo e 150.000 linhas\n",
        "import pandas as pd\n",
        "\n",
        "header_list = [\"id\", \"score\"]\n",
        "df = pd.read_csv('/content/drive/MyDrive/TrabalhoFT/corona_tweets_463.csv',nrows=150000, usecols=[0,1],names=header_list,skip_blank_lines=True)\n",
        "x = df[['id','score']]#Read two columns\n",
        "#x.columns = ['id', 'score']\n",
        "print(x)\n",
        "\n",
        "y =  x[['id']] #Read a column\n",
        "\n",
        "print(y)\n",
        "\n",
        "#Mostrando quantas linhas e colunas temos no DataFrame\n",
        "y.shape\n",
        "\n",
        "\n",
        "#Instalando a biblioteca twarc para Hydaratar os Tweets\n",
        "%pip install twarc\n",
        "%pip install jsonlines\n",
        "\n",
        "#Configurando o twarc para ler os tweets\n",
        "from twarc import Twarc\n",
        "\n",
        "\n",
        "consumer_key = \"TqOMbK44mhFn8P4Rviae3sM5Y\" #@param {type:\"string\"}\n",
        "consumer_secret = \"Qkog3ytEszYMQ531yPfjXupPNPOoh973v1YP1Oe6YZYWNY19Ba\" #@param {type:\"string\"}\n",
        "access_token = \"1408437861624553480-TiIJbrPCWDQVE7MROBFZvJVho0dyLu\" #@param {type:\"string\"}\n",
        "access_token_secret = \"iqyl70jym6MNvRVBh7Kh8qzZYi5T5CmzZHcvBnDeL8KLf\" #@param {type:\"string\"}\n",
        "\n",
        "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
        "\n",
        "#Configurando o arquivo de saida\n",
        "\n",
        "final_tweet_ids_filename = \"/content/drive/MyDrive/TrabalhoFT/IDtweets.csv\" #@param {type: \"string\"}\n",
        "output_filename = \"/content/drive/MyDrive/TrabalhoFT/output.csv\" #@param {type: \"string\"}\n",
        "\n",
        "#apagando o arquivo anterior\n",
        "file = '/content/drive/MyDrive/TrabalhoFT/output.txt'\n",
        "if(os.path.exists(file) and os.path.isfile(file)):\n",
        "  os.remove(file)\n",
        "  print(\"file deleted\")\n",
        "else:\n",
        "  print(\"file not found\")\n",
        "\n",
        "#apagando o arquivo anterior\n",
        "if(os.path.exists(output_filename) and os.path.isfile(output_filename)):\n",
        "  os.remove(output_filename)\n",
        "  print(\"file deleted\")\n",
        "else:\n",
        "  print(\"file not found\")\n",
        "\n",
        "\n",
        "#Definindo os id Tweets para Hydratar.\n",
        "y.to_csv('/content/drive/MyDrive/TrabalhoFT/IDtweets.csv', encoding='utf-8', index=False)\n",
        "\n",
        "for tweet in t.hydrate('/content/drive/MyDrive/TrabalhoFT/IDtweets.csv'):\n",
        "    print(tweet['full_text'])\n",
        "    print(tweet['id'])\n",
        "\n",
        "import jsonlines, json\n",
        "# Stores hydrated tweets here as jsonl objects\n",
        "# Contains one json object per line\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".txt\"\n",
        "ids = []\n",
        "with open(final_tweet_ids_filename, \"r\") as ids_file:\n",
        "    ids = ids_file.read().split()\n",
        "hydrated_tweets = []\n",
        "ids_to_hydrate = set(ids)\n",
        "\n",
        "\n",
        "# Looks at the output file for already hydrated tweets\n",
        "if os.path.isfile(output_json_filename):\n",
        "    with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "        for i in reader.iter(type=dict, skip_invalid=True):\n",
        "            # These tweets have already been hydrated. So remove them from ids_to_hydrate\n",
        "            hydrated_tweets.append(i)\n",
        "            ids_to_hydrate.remove(i[\"id_str\"])\n",
        "            print(\"ARQUIVO\")\n",
        "print(\"Total IDs: \" + str(len(ids)) + \", IDs to hydrate: \" + str(len(ids_to_hydrate)))\n",
        "print(\"Hydrated: \" + str(len(hydrated_tweets)))\n",
        "\n",
        "count = len(hydrated_tweets)\n",
        "start_index = count # The index from where tweets haven't been saved to the output_json_file\n",
        "# Stores hydrated tweets to output_json_file every num_save iterations.\n",
        "num_save  = 1000\n",
        "\n",
        "# Now, use twarc and start hydrating\n",
        "for tweet in t.hydrate(ids_to_hydrate):\n",
        "    hydrated_tweets.append(tweet)\n",
        "    count += 1\n",
        "    # If num_save iterations have passed,\n",
        "    if (count % num_save) == 0:\n",
        "        # Open the output file\n",
        "        # NOTE: Even if the code stops during IO, only tweets from the current iteration are lost.\n",
        "        # Older tweets are preserved as the file is written in append mode.\n",
        "        with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "            print(\"Started IO\")\n",
        "            # Now write the tweets from start_index. The other tweets don't have to be written\n",
        "            # as they were already written in a previous iteration or run.\n",
        "            for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "                writer.write(hydrated_tweet)\n",
        "            print(\"Finished IO\")\n",
        "        print(\"Saved \" + str(count) + \" hydrated tweets.\")\n",
        "        # Now, since everything has been written. Reset start_index\n",
        "        start_index = count\n",
        "# There might be tweets unwritten in the last iteration if the count is not a multiple of num_tweets.\n",
        "# In that case, just write out the remainder of tweets.\n",
        "if count != start_index:\n",
        "    print(\"Here with start_index\", start_index)\n",
        "    with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "        for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "           writer.write(hydrated_tweet)\n",
        "\n",
        "# Convert jsonl to csv\n",
        "import csv, jsonlines\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".txt\"\n",
        "keyset = [\"created_at\", \"id\", \"id_str\", \"full_text\", \"source\", \"truncated\", \"in_reply_to_status_id\",\n",
        "          \"in_reply_to_status_id_str\", \"in_reply_to_user_id\", \"in_reply_to_user_id_str\", \n",
        "          \"in_reply_to_screen_name\", \"user\", \"coordinates\", \"place\", \"quoted_status_id\",\n",
        "          \"quoted_status_id_str\", \"is_quote_status\", \"quoted_status\", \"retweeted_status\", \n",
        "          \"quote_count\", \"reply_count\", \"retweet_count\", \"favorite_count\", \"entities\", \n",
        "          \"extended_entities\", \"favorited\", \"retweeted\", \"possibly_sensitive\", \"filter_level\", \n",
        "          \"lang\", \"matching_rules\", \"current_user_retweet\", \"scopes\", \"withheld_copyright\", \n",
        "          \"withheld_in_countries\", \"withheld_scope\", \"geo\", \"contributors\", \"display_text_range\",\n",
        "          \"quoted_status_permalink\"]       \n",
        "hydrated_tweets = []\n",
        "with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "    for i in reader.iter(type=dict, skip_invalid=True):\n",
        "        hydrated_tweets.append(i)\n",
        "with  open(output_filename, \"w+\") as output_file:\n",
        "    d = csv.DictWriter(output_file, keyset)\n",
        "    d.writeheader()\n",
        "    d.writerows(hydrated_tweets)\n",
        "\n",
        "df_tweets = pd.read_csv('/content/drive/MyDrive/TrabalhoFT/output.csv')\n",
        "\n",
        "# select desired columns\n",
        "df_tweets = df_tweets[['id', 'full_text']]\n",
        "df_text_tweets = df_tweets[['full_text']]\n",
        "\n",
        "print(df_tweets[['full_text']])\n",
        "m = pd.merge(x, df_tweets, how = 'left', on = 'id')\n",
        "\n",
        "#write to the file (tab separated)\n",
        "m.to_csv('Final.csv', sep=',', index=False)\n",
        "\n",
        "# --------------------------- PRE PROCESSAMENTO ------------------------------\n",
        "#Começando a parte do pré-processamento\n",
        "\n",
        "#[Jfranciscon] Definição das funções para preprocessamento\n",
        "#!pip install google_trans_new\n",
        "!pip install git+https://github.com/stanfordnlp/stanza.git\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from textblob import TextBlob\n",
        "import stanza\n",
        "stanza.download('en')\n",
        "#from google_trans_new import google_translator\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import numpy as np\n",
        "\n",
        "nlp = stanza.Pipeline(lang='en')\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "        '''\n",
        "        Função para limpar o tweet removendo links, caracteres especiais\n",
        "        utilizando regex.\n",
        "        '''\n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "\n",
        "def translate_tweet(tweet):\n",
        "        '''\n",
        "        Função para traduzir o tweet portugues para inglês.\n",
        "        '''\n",
        "        translator = google_translator()\n",
        "        tweet_en = translator.translate(tweet, lang_src='pt', lang_tgt='en')\n",
        "        return tweet_en\n",
        "    \n",
        "def stopwords_tweet(tweet):\n",
        "        '''\n",
        "        Função para remover stopwords\n",
        "        '''\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        word_tokens = word_tokenize(tweet)\n",
        "        \n",
        "        filtered_sentence = []\n",
        "        for w in word_tokens:\n",
        "            if w not in stop_words:\n",
        "                filtered_sentence.append(w)\n",
        "                \n",
        "        return ' '.join(filtered_sentence)\n",
        "    \n",
        "def lemma_tweet(tweet):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tweet_lower = tweet.lower()\n",
        "        # define função para lemmatize cada palavra com sua POS tag\n",
        "        # POS_TAGGER_FUNCTION : TYPE 1\n",
        "        def pos_tagger(nltk_tag):\n",
        "            if nltk_tag.startswith('J'):\n",
        "                return wordnet.ADJ\n",
        "            elif nltk_tag.startswith('V'):\n",
        "                return wordnet.VERB\n",
        "            elif nltk_tag.startswith('N'):\n",
        "                return wordnet.NOUN\n",
        "            elif nltk_tag.startswith('R'):\n",
        "                return wordnet.ADV\n",
        "            elif nltk_tag.startswith('A'):\n",
        "                return wordnet.ADJ\n",
        "            elif nltk_tag.startswith('S'):\n",
        "                return wordnet.ADJ_SAT\n",
        "            else:          \n",
        "                return None\n",
        "\n",
        "        pos_tagged = nltk.pos_tag(nltk.word_tokenize(tweet_lower))\n",
        "        wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
        "        \n",
        "        lemmatized_sentence = [] #cria a lista para armazenar cada palavra na forma basica\n",
        "        for word, tag in wordnet_tagged:\n",
        "            if tag is None:\n",
        "                # se não tem uma tag, armazena a palavra como está\n",
        "                lemmatized_sentence.append(word)\n",
        "            else:        \n",
        "                # caso contrário seleciona a tag e retorna a forma basica\n",
        "                lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))        \n",
        " \n",
        "        return ' '.join(lemmatized_sentence)    \n",
        "    \n",
        "def get_tweet_sentiment(tweet):\n",
        "        '''\n",
        "        Função para classificar os sentimentos em positivo/negativo/neutro do tweet coletado\n",
        "        1. faz a tradução do portugues para ingles usando a nova api do google (prob na antinga)\n",
        "        2. usando o metodo textblob no tweet traduzido (tweet_en)\n",
        "        \n",
        "        '''\n",
        "        # INICIO das etapas de PREPROCESSAMENTO DO TWEET\n",
        "        # 1. traduz para inglês\n",
        "        #tweet_en = translate_tweet(tweet)\n",
        "        # 2. limpa caracters, hashtags, http, pontuação etc\n",
        "        tweet_en = clean_tweet(tweet)\n",
        "        # 3. identifica e remove stopwords (palavras irrelevantes)\n",
        "        tweet_en = stopwords_tweet(tweet_en)\n",
        "        # 4. identifica a forma morfologica e converte a palavra na forma básica\n",
        "        tweet_en = lemma_tweet(tweet_en)\n",
        "        \n",
        "        # TEXTBLOB faz a analise de sentimento com o tweet preprocessado\n",
        "        analysis = TextBlob(tweet_en)\n",
        "        neutral_thresh = 0.05\n",
        "        # define o sentimento-->sentiment\n",
        "        if analysis.sentiment.polarity >= neutral_thresh:\n",
        "            return 'positivo'\n",
        "        elif analysis.sentiment.polarity <= -(neutral_thresh):\n",
        "            return 'negativo'\n",
        "        else:\n",
        "            return 'neutro'\n",
        "\n",
        "def get_tweet_sentiment_STANZA(tweet):\n",
        "        # A funcao obtem (media) score do sentimento pelo Stanza para cada tweet\n",
        "        # Menos 1, de modo a trazer a faixa de pontuação de [0,2] a [-1,1]\n",
        "        def stanza_analyze(Text):\n",
        "            document = nlp(Text)\n",
        "            return np.mean([(i.sentiment - 1) for i in document.sentences]) \n",
        "               \n",
        "        analysis = stanza_analyze(tweet)\n",
        "        \n",
        "        neutral_thresh = 0.05\n",
        "        # define o sentimento-->sentiment\n",
        "        if analysis >= neutral_thresh:\n",
        "            return 'positivo'\n",
        "        elif analysis <= -(neutral_thresh):\n",
        "            return 'negativo'\n",
        "        else:\n",
        "            return 'neutro'\n",
        "\n",
        "def converte_sentimento_original(sentiment):\n",
        "        neutral_thresh = 0.05\n",
        "        if sentiment >= neutral_thresh:\n",
        "            return 'positivo'\n",
        "        elif sentiment <= -(neutral_thresh):\n",
        "            return 'negativo'\n",
        "        else:\n",
        "            return 'neutro'\n",
        "\n",
        "\n",
        "df_tweets['sentimento'] = df_tweets['full_text'].map(get_tweet_sentiment)\n",
        "df_tweets['sentimento_STANZA'] = df_tweets['full_text'].map(get_tweet_sentiment_STANZA)\n",
        "\n",
        "# pega os tweets positivos da lista de tweets\n",
        "ptweets = len(df_tweets.loc[df_tweets['sentimento'] == 'positivo'])\n",
        "# porcentagem dos tweets positivos\n",
        "print(\"% tweets positivos TEXTBLOB: {} %\".format(100*(ptweets/len(df_tweets))))\n",
        "# pega os tweets negativos da lista de tweets\n",
        "ntweets = len(df_tweets.loc[df_tweets['sentimento'] == 'negativo'])\n",
        "# porcentagem dos tweets negativos\n",
        "print(\"% tweets negativos TEXTBLOB: {} %\".format(100*(ntweets/len(df_tweets))))\n",
        "# porcentagem dos tweets neutros\n",
        "print(\"% tweets neutros TEXTBLOB: {} % \\\n",
        "    \".format(100*((len(df_tweets) -(ntweets+ptweets))/len(df_tweets))))\n",
        "\n",
        "# pega os tweets positivos da lista STANZA\n",
        "ptweets = len(df_tweets.loc[df_tweets['sentimento_STANZA'] == 'positivo'])\n",
        "# porcentagem dos tweets positivos STANZA\n",
        "print(\"% tweets positivos STANZA: {} %\".format(100*(ptweets/len(df_tweets))))\n",
        "# pega os tweets negativos da lista STANZA \n",
        "ntweets = len(df_tweets.loc[df_tweets['sentimento_STANZA'] == 'negativo'])\n",
        "# porcentagem dos tweets negativos STANZA\n",
        "print(\"% tweets negativos STANZA: {} %\".format(100*(ntweets/len(df_tweets))))\n",
        "# porcentagem dos tweets neutros STANZA\n",
        "print(\"% tweets neutros STANZA: {} % \\\n",
        "    \".format(100*((len(df_tweets) -(ntweets+ptweets))/len(df_tweets))))\n",
        "\n",
        "df_original = pd.read_csv('/content/drive/MyDrive/TrabalhoFT/Final.csv', delimiter=',', usecols=[0,1])\n",
        "df_original['sentimento_original'] = df_original['score'].map(converte_sentimento_original)\n",
        "\n",
        "# pega os tweets positivos da lista de tweets originais\n",
        "ptweets = len(df_original.loc[df_original['sentimento_original'] == 'positivo'])\n",
        "# porcentagem dos tweets positivos originais\n",
        "print(\"% tweets positivos ORIGINAIS: {} %\".format(100*(ptweets/len(df_original))))\n",
        "# pega os tweets negativos da lista de tweets originais\n",
        "ntweets = len(df_original.loc[df_original['sentimento_original'] == 'negativo'])\n",
        "# porcentagem dos tweets negativos originais\n",
        "print(\"% tweets negativos ORIGINAIS: {} %\".format(100*(ntweets/len(df_original))))\n",
        "# porcentagem dos tweets neutros originais\n",
        "print(\"% tweets neutros ORIGINAIS: {} % \\\n",
        "    \".format(100*((len(df_original) -(ntweets+ptweets))/len(df_original))))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "current directory is : /content/drive/MyDrive/TrabalhoFT\n",
            "                         id     score\n",
            "0       1407917783569031170  0.000000\n",
            "1       1407917783824801792  0.383333\n",
            "2       1407917783929655303  0.250000\n",
            "3       1407917783971684356  0.166667\n",
            "4       1407917784269529091  0.100000\n",
            "...                     ...       ...\n",
            "149995  1407953168932220928  0.910000\n",
            "149996  1407953169229955077  0.150000\n",
            "149997  1407953168848211973  0.000000\n",
            "149998  1407953169418756096 -0.100000\n",
            "149999  1407953169502674945  0.227273\n",
            "\n",
            "[150000 rows x 2 columns]\n",
            "                         id\n",
            "0       1407917783569031170\n",
            "1       1407917783824801792\n",
            "2       1407917783929655303\n",
            "3       1407917783971684356\n",
            "4       1407917784269529091\n",
            "...                     ...\n",
            "149995  1407953168932220928\n",
            "149996  1407953169229955077\n",
            "149997  1407953168848211973\n",
            "149998  1407953169418756096\n",
            "149999  1407953169502674945\n",
            "\n",
            "[150000 rows x 1 columns]\n",
            "Collecting twarc\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/94/ecbc981c29c375b89903b12adf4b8007882c3c784aee304d7c5be8d8910d/twarc-2.3.7.tar.gz (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from twarc) (2.8.1)\n",
            "Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.7/dist-packages (from twarc) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from twarc) (4.41.1)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from twarc) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from twarc) (7.1.2)\n",
            "Collecting click-plugins\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Collecting click-config-file\n",
            "  Downloading https://files.pythonhosted.org/packages/28/16/c71980d10b75cf4ee2c71bb946c3326a18585254399aac64a5e79cfba5a5/click_config_file-0.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->twarc) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests_oauthlib->twarc) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests_oauthlib->twarc) (2.23.0)\n",
            "Collecting configobj>=5.0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests_oauthlib->twarc) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests_oauthlib->twarc) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests_oauthlib->twarc) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests_oauthlib->twarc) (2.10)\n",
            "Building wheels for collected packages: twarc, configobj\n",
            "  Building wheel for twarc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twarc: filename=twarc-2.3.7-cp37-none-any.whl size=49603 sha256=403bff4490f4f7420c8ee5292c86538b4d75e98e9e29073ca011cacc017d2a62\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/14/96/bfc140625d59cf940bde14b66a1158d08a3062159982822195\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp37-none-any.whl size=34547 sha256=fe172882cf28ca784cbb3d4a47e22db61cccae25ac1df804dc33cb7ffea8f844\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "Successfully built twarc configobj\n",
            "Installing collected packages: click-plugins, configobj, click-config-file, twarc\n",
            "Successfully installed click-config-file-0.6.0 click-plugins-1.1.1 configobj-5.0.6 twarc-2.3.7\n",
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/58/06f430ff7607a2929f80f07bfd820acbc508a4e977542fefcc522cde9dff/jsonlines-2.0.0-py3-none-any.whl\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-2.0.0\n",
            "file deleted\n",
            "file deleted\n",
            "Total IDs: 150001, IDs to hydrate: 149998\n",
            "Hydrated: 0\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 1000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 2000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 3000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 4000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 5000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 6000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 7000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 8000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 9000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 10000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 11000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 12000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 13000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 14000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 15000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 16000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 17000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 18000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 19000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 20000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 21000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 22000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 23000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 24000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 25000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 26000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 27000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 28000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 29000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 30000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 31000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 32000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 33000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 34000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 35000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 36000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 37000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 38000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 39000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 40000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 41000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 42000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 43000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 44000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 45000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 46000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 47000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 48000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 49000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 50000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 51000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 52000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 53000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 54000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 55000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 56000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 57000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 58000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 59000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 60000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 61000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 62000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 63000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 64000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 65000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 66000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 67000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 68000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 69000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 70000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 71000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 72000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 73000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 74000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 75000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 76000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 77000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 78000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 79000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 80000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 81000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 82000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 83000 hydrated tweets.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:twarc:rate limit exceeded: sleeping 275.261682510376 secs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Started IO\n",
            "Finished IO\n",
            "Saved 84000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 85000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 86000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 87000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 88000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 89000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 90000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 91000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 92000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 93000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 94000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 95000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 96000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 97000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 98000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 99000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 100000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 101000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 102000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 103000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 104000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 105000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 106000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 107000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 108000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 109000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 110000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 111000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 112000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 113000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 114000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 115000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 116000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 117000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 118000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 119000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 120000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 121000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 122000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 123000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 124000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 125000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 126000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 127000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 128000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 129000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 130000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 131000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 132000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 133000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 134000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 135000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 136000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 137000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 138000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 139000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 140000 hydrated tweets.\n",
            "Here with start_index 140000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (12,36) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                full_text\n",
            "0       @Belagavi_infra @MoHFW_INDIA There is no use o...\n",
            "1       RT @dezying: With Occam's Razor, the plausible...\n",
            "2       @CTVNews You mean the experimental vaccine we ...\n",
            "3       RT @LukeGoslingMP: It is way past time that PM...\n",
            "4       RT @SlimJosa: I don’t think some of you unders...\n",
            "...                                                   ...\n",
            "140049  RT @JandTContent: .@GovernorLittle @GovHawaii ...\n",
            "140050  COVID-19 Vaccination appointments available at...\n",
            "140051  RT @sridhar1085: The centre told the Supreme C...\n",
            "140052  RT @FaerieWhings: Cuba did it again, with no p...\n",
            "140053  RT @TwitterMoments: The Delta variant of COVID...\n",
            "\n",
            "[140054 rows x 1 columns]\n",
            "Collecting git+https://github.com/stanfordnlp/stanza.git\n",
            "  Cloning https://github.com/stanfordnlp/stanza.git to /tmp/pip-req-build-gc8p1ujw\n",
            "  Running command git clone -q https://github.com/stanfordnlp/stanza.git /tmp/pip-req-build-gc8p1ujw\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza==1.2.1) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza==1.2.1) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza==1.2.1) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza==1.2.1) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza==1.2.1) (4.41.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza==1.2.1) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2.1) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza==1.2.1) (3.7.4.3)\n",
            "Building wheels for collected packages: stanza\n",
            "  Building wheel for stanza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stanza: filename=stanza-1.2.1-cp37-none-any.whl size=642799 sha256=bc32698243fabba2e92f40eef18cf0985505a70cc1ff5b92f3c3956cf3609bf5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wmo1xaxh/wheels/01/78/62/61318466c5384e887fa693f09fcd651b0d0892bc327c009fcf\n",
            "Successfully built stanza\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2.1\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d98d804ada834ca68b7ced0642d33dc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading https://raw.githubusercontent.com/stanfordnlp…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:stanza:Downloading default packages for language: en (English)...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "114151d37cab49b59f37d910be7e47e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading http://nlp.stanford.edu/software/stanza/1.2.1…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n",
            "INFO:stanza:Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | combined  |\n",
            "| pos       | combined  |\n",
            "| lemma     | combined  |\n",
            "| depparse  | combined  |\n",
            "| sentiment | sstplus   |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "INFO:stanza:Use device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Loading: sentiment\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5qjW_3J5xJV"
      },
      "source": [
        "#Código para conexão a pesquisa de tweets.\n",
        "!pip install tweepy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17np5I0N591n"
      },
      "source": [
        "import tweepy\n",
        "import webbrowser\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8fA1DL76Cgc"
      },
      "source": [
        "consumer_key = \"TqOMbK44mhFn8P4Rviae3sM5Y\"\n",
        "consumer_secret = \"Qkog3ytEszYMQ531yPfjXupPNPOoh973v1YP1Oe6YZYWNY19Ba\"\n",
        "callback_uri = 'oob'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMOGJ54N6IU5"
      },
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret, callback_uri)\n",
        "redirect_url = auth.get_authorization_url()\n",
        "print(redirect_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F0-MREF6NjF"
      },
      "source": [
        "user_pin_input = input(\"Digite o pin aqui: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gvxZzV_6VVs"
      },
      "source": [
        "auth.get_access_token(user_pin_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1xdc3A26Wjs"
      },
      "source": [
        "print(auth.access_token, auth.access_token_secret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACcYN2nA6ZWO"
      },
      "source": [
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlSNBz0d6a7q"
      },
      "source": [
        "me = api.me()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcDWQ0xh6cIm"
      },
      "source": [
        "print(me.screen_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wop-5bS7X1DO"
      },
      "source": [
        "print(api.get_status(id = '1224527382494662659'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "379BGMU4av6w"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Jun 17 14:20:10 2021\n",
        "\n",
        "@author: jfrancis\n",
        "\"\"\"\n",
        "!pip install google_trans_new\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from textblob import TextBlob\n",
        "from google_trans_new import google_translator\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "\n",
        "class TwitterClient(object):\n",
        "    '''\n",
        "    Classe genérica do Twitter para analise de sentimentos\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        metodo de inicialização \n",
        "        '''\n",
        "        # keys e tokens geradas no  dev console com meu usuario projeto twitter Unicamp_ml\n",
        "        consumer_key = 'e9RRxn8rGRFijTZfG73VtdniU'\n",
        "        consumer_secret = 'wvW8f7S0C60MMyCwGgpr2y3ypc0VhWXJsDb8edxiWqArtp1DuH'\n",
        "        access_token = '1405577872413188096-dsPwQO9T8diH0E0xm2NaGccl0pjDqa'\n",
        "        access_token_secret = 'f4huEGvJr9vZsX9t2uZRchYBrJul9iNuRUqY8CGMRO2mA'\n",
        "\n",
        "        # tentando autenticação\n",
        "        try:\n",
        "            # criação do OAuthHandler object\n",
        "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "            # set access token e secret\n",
        "            self.auth.set_access_token(access_token, access_token_secret)\n",
        "            # criando o tweepy API object para coletar os tweets\n",
        "            self.api = tweepy.API(self.auth)\n",
        "        except:\n",
        "            print(\"Erro: Falha na autenticação\")\n",
        "\n",
        "    \n",
        "\n",
        "    def get_tweets(self, query, count):\n",
        "        '''\n",
        "        Função principal para coletar os tweets e analisá-los\n",
        "        '''\n",
        "        # cria uma lista vazia para armazenar os tweets analizados\n",
        "        # talvez aqui poderiamos definir o pandas ou dataset para armazenar\n",
        "        # como o exemplo é simples, sem as funções de mineração então uma lista serve \n",
        "        tweets = []\n",
        "\n",
        "        try:\n",
        "            # chama a twitter api para coletar os tweets\n",
        "            fetched_tweets = self.api.search(q = query, count = count)\n",
        "\n",
        "            # analisa os tweets um a um\n",
        "            for tweet in fetched_tweets:\n",
        "                # cria um dicionario para armazenar os parametros requeridos de um tweet por exemplo \n",
        "                # parametro text, parametro sentiment\n",
        "                parsed_tweet = {}\n",
        "\n",
        "                # salva o texto do tweet\n",
        "                parsed_tweet['text'] = tweet.text\n",
        "                # salva o sentimento do tweet\n",
        "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
        "\n",
        "                # inclui o tweet analisado na lista de tweets\n",
        "                if tweet.retweet_count > 0:\n",
        "                    # se o tweet tem retweets garante que vai ser incluido na lista uma unica vez\n",
        "                    if parsed_tweet not in tweets:\n",
        "                        tweets.append(parsed_tweet)\n",
        "                else:\n",
        "                    tweets.append(parsed_tweet)\n",
        "\n",
        "            # retorna os tweets analisados\n",
        "            return tweets\n",
        "\n",
        "        except tweepy.TweepError as e:\n",
        "            # imprime os erros se existirem\n",
        "            print(\"Erro : \" + str(e))\n",
        "\n",
        "# cria o objeto do TwitterClient Class\n",
        "api = TwitterClient()\n",
        "# chama a função para coletar os tweets\n",
        "tweets = api.get_tweets(query = 'covid vacinação', count = 200)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "my_array = np.array(tweets)\n",
        "print (my_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZycHq8QuaqT"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "  \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "  \n",
        "  \n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH3e9Pe4xtCl"
      },
      "source": [
        "link = 'https://drive.google.com/file/d/16OgX2Hm5w2GNRvjb-iyfJHc52JJ4-E2v/view?usp=sharing'\n",
        "  \n",
        "import pandas as pd\n",
        "  \n",
        "# to get the id part of the file\n",
        "id = link.split(\"/\")[-2]\n",
        "  \n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('1_corona_tweets_463.csv')  \n",
        "  \n",
        "df = pd.read_csv('1_corona_tweets_463.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}